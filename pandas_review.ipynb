{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa3be9c",
   "metadata": {},
   "source": [
    "## Installation Of Pandas\n",
    "<li>Go to your terminal, open and activate your virtual environment and then use the following commands for installing pandas.</li>\n",
    "\n",
    "<code>\n",
    "    pip install pandas\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28308f7b",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "<li>We need to import pandas if we want to create a pandas dataframe and perform any analysis on them.</li>\n",
    "<li>We can import pandas package using the following command:</li>\n",
    "<code>\n",
    "    import pandas as pd\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cff6e5",
   "metadata": {},
   "source": [
    "### How To Load Pandas Dataframe From Csv files\n",
    "\n",
    "<li>We can load a csv file and create a dataframe out of the data present inside a csv file using pandas.</li>\n",
    "<li>We have <b>.read_csv()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea56333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe25b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1416453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9029fb4",
   "metadata": {},
   "source": [
    "#### Write a pandas dataframe to a csv file\n",
    "<li>We can write a pandas dataframe to a csv file using .to_csv() method.</li>\n",
    "<li>You can specify any name to the csv file while writing a pandas dataframe into a csv file.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d2b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c4983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd24f497",
   "metadata": {},
   "source": [
    "#### Using head() and tail() method to see top 5 and last 5 rows\n",
    "<li>To view the first few rows of our dataframe, we can use the DataFrame.head() method.</li>\n",
    "<li>By default, it returns the first five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>\n",
    "\n",
    "<li>Similarly, to view the last few rows of our dataframe, we can use the DataFrame.tail() method.</li>\n",
    "<li>By default, it returns the last five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aaa263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365817a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4580547",
   "metadata": {},
   "source": [
    "#### Finding the column names from the dataframe\n",
    "<li>We have df.columns attributes to check the name of columns in the pandas dataframe.</li>\n",
    "<li>Similarly, we have df.values attributes to check the data present in the pandas dataframe.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbbc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0df16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86abadee",
   "metadata": {},
   "source": [
    "#### Datatypes Information\n",
    "<li>We can get the shape of the dataset using <b>.shape attribute.</li>\n",
    "<li><b>.shape</b> attrib ute returns the tuple datatype containing the number of rows and number of columns in the dataset.</li>\n",
    "<li>If we wanted an overview of all the dtypes used in our dataframe, we can use <b>.info()</b> method.</li>\n",
    "<li>Note that <b>DataFrame.info()</b> prints the information, rather than returning it, so we can't assign it to a variable.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce487992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e65da4a0",
   "metadata": {},
   "source": [
    "#### Checking the type of your dataframe \n",
    "<li>Another feature that makes pandas better for working with data is that dataframes can contain more than one data type.</li>\n",
    "<li>Axis values can have string labels, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with multiple data types: including integer, float, and string.</li>\n",
    "<li>We can use the DataFrame.dtypes attribute (similar to NumPy) to return information about the types of each column.</li>\n",
    "<li>When we import data, pandas attempts to guess the correct dtype for each column.</li>\n",
    "<li>Generally, pandas does well with this, which means we don't need to worry about specifying dtypes every time we start to work with data.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c8bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca26d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1895a82e",
   "metadata": {},
   "source": [
    "#### Checking the null values in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665857c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f4d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eed2a661",
   "metadata": {},
   "source": [
    "#### set_index() and reset_index() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c8cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f4240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11c0ca16",
   "metadata": {},
   "source": [
    "#### Selecting a column from a pandas DataFrame\n",
    "\n",
    "<li>Since our axis in pandas have labels, we can select data using those labels.</li> \n",
    "<li>Unlike in NumPy, we donot need to know the exact index location of a pandas dataframe.</li>\n",
    "<li>To do this, we can use the DataFrame.loc[] attribute. The syntax for DataFrame.loc[] is:</li>\n",
    "<code>\n",
    "df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "<li>We can use the following shortcut to select a single column:</li>\n",
    "<code>\n",
    "df[\"column_name\"]\n",
    "</code>\n",
    "\n",
    "<li>This style of selecting columns is very common.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0da34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c37e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c08e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0103aec",
   "metadata": {},
   "source": [
    "#### Pandas Series\n",
    "<li>Series is the pandas type for one-dimensional objects.</li>\n",
    "<li>Anytime you see a 1D pandas object, it will be a series. Anytime you see a 2D pandas object, it will be a dataframe.</li>\n",
    "<li>A dataframe is a collection of series objects, which is similar to how pandas stores the data behind the scenes.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2eafe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a90c27ad",
   "metadata": {},
   "source": [
    "#### Adding a column in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4d709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee01c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36009daf",
   "metadata": {},
   "source": [
    "### Selecting Multiple Columns From the DataFrame\n",
    "\n",
    "![](images/selecting_columns.png)\n",
    "\n",
    "<li>We can select multiple columns from the dataframe by using the following codes:</li>\n",
    "<code>\n",
    "    df.loc[:, [\"col1\", \"col2\"]]\n",
    "</code>\n",
    "\n",
    "<li>We can use syntax shortcuts for selecting multiple columns by using the following syntax:</li>\n",
    "<code>\n",
    "    df[[\"col1\", \"col2\"]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6417c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2b83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "722c9447",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "<li>Read 'car_details.csv' file and create a pandas dataframe from it.</li>\n",
    "<li>Then only select <b>'name'</b>, <b>'selling price'</b> and <b>'km_driven'</b> columns from the dataframe.</li>\n",
    "\n",
    "![](images/selecting_3_cols.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8208896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c2a9f1",
   "metadata": {},
   "source": [
    "#### Selecting Rows From A Pandas DataFrame\n",
    "\n",
    "<li>Now that we've learned how to select columns by label, let's learn how to select rows using the labels of the index axis.</li>\n",
    "<li>We can use the same syntax to select rows from a dataframe as we do for columns:</li>\n",
    "<code>\n",
    "    df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6a3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d41e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bd8d1d7",
   "metadata": {},
   "source": [
    "### Selecting Multiple Rows From the DataFrame\n",
    "\n",
    "![](images/selecting_multiple_rows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acad68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462a842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a9ed09",
   "metadata": {},
   "source": [
    "#### Indexing & Slicing In Pandas DataFrame\n",
    "\n",
    "<li>We can slice a dataset from their rows as well as columns.</li>\n",
    "<li>If we have (5,5) shape data and we want first three rows and first three columns then we need to slice both rows and columns to get a desired shape.</li>\n",
    "<li>We have df.iloc() method which we can use to do indexing as well as slicing in a dataframe.</li>\n",
    "<li>Let's practice .iloc() method.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac5915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf83421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35fde363",
   "metadata": {},
   "source": [
    "#### Datatype Conversion In Pandas\n",
    "\n",
    "<li>Pandas astype() is the one of the most important methods. It is used to change data type of a series.</li>\n",
    "<li>When a pandas dataframe is created from a csv file,the data type is set automatically.</li>\n",
    "<li>The datatype will not be what it actually should be at times and this is where we can use astype()  to get desired datatype.</li>\n",
    "<li>For example, a salary column could be imported as string but to do operations we have to convert it into float.</li>\n",
    "<li>astype() is used to do such data type conversions.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2651a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667849b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28be873",
   "metadata": {},
   "source": [
    "### info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a884f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0123afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eab1592",
   "metadata": {},
   "source": [
    "#### Value Counts Method\n",
    "\n",
    "<li>Since series and dataframes are two distinct objects, they have their own unique methods.</li>\n",
    "\n",
    "<li>Let's look at an example of a series method - the Series.value_counts() method.</li>\n",
    "\n",
    "<li>This method displays each unique non-null value in a column and their counts in order.</li>\n",
    "\n",
    "<li>value_counts() is a series only method, we get the following error if we try to use it for dataframes:</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c34aaa",
   "metadata": {},
   "source": [
    "#### Vecotrized Operations In Pandas\n",
    "\n",
    "<li>We'll explore how pandas uses many of the concepts we learned in the NumPy.</li>\n",
    "<li>Because pandas is designed to operate like NumPy, a lot of concepts and methods from Numpy are supported.</li>\n",
    "<li>Recall that one of the ways NumPy makes working with data easier is with vectorized operations.</li>\n",
    "<li>Just like with NumPy, we can use any of the standard Python numeric operators with series, including:</li>\n",
    "<code>\n",
    "    series_a + series_b - Addition\n",
    "    series_a - series_b - Subtraction\n",
    "    series_a * series_b - Multiplication\n",
    "    series_a / series_b - Division\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4144ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0af8ea2e",
   "metadata": {},
   "source": [
    "#### Some Statistical Functions In Pandas\n",
    "\n",
    "<li>Like NumPy, Pandas supports many descriptive stats methods such as mean, median, mode, min, max and so on.</li>\n",
    "<li>Here are a few of the most useful ones.</li>\n",
    "<code>\n",
    "Series.max()\n",
    "Series.min()\n",
    "Series.mean()\n",
    "Series.median()\n",
    "Series.mode()\n",
    "Series.sum()\n",
    "</code>\n",
    "<li>We can calculate the average value of a particular column(series) using df.column_name.mean().</li>\n",
    "<li>For calculating the minimum value in a particular column(series), we can use df.column_name.min().</li>\n",
    "<li>Similarly, for calculating the maximum value in a particular column(series), we can use df.column_name.max().</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529ad52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ced67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38566eab",
   "metadata": {},
   "source": [
    "#### Finding the descriptive statistics of the dataframe using .describe() method\n",
    "\n",
    "<li>Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values.</li>\n",
    "<li>describe() method in Pandas is used to compute descriptive statistics for all of your numeric columns.</li>\n",
    "<li>Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types.</li>\n",
    "<li>The output will vary depending on what is provided.</li>\n",
    "<li>If we want to see the descriptive statistics of an object datatype then we have to specify <b>df.describe(include = \"O\")</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06873c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25990746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb376376",
   "metadata": {},
   "source": [
    "#### Assigning Values With Pandas\n",
    "\n",
    "<li>Just like in NumPy, the same techniques that we use to select data could be used for assignment.</li>\n",
    "\n",
    "<li>When we selected a whole column by label and used assignment, we assigned the value to every item in that column.</li>\n",
    "\n",
    "<li>By providing labels for both axes, we can assign them to a single value within our dataframe.</li>\n",
    "\n",
    "<code>\n",
    "    df.loc[row_label, col_label] = assignment_value\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fd44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543c9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26dda196",
   "metadata": {},
   "source": [
    "#### Using Boolean Indexing With Pandas Objects (Selection With Condition In Pandas)\n",
    "<li>We can assign a value by using row label and column label in pandas.</li>\n",
    "<li>But what if we need to assign a same value to a group of similar rows with the same criteria.</li>\n",
    "<li> Instead, we can use boolean indexing to change all rows that meet the same criteria, just like we did with NumPy.</li>\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>Equals: df['series'] == value</li>\n",
    "    <li>Not Equals: df['series'] != value</li>\n",
    "    <li>Less than: df['series'] < value</li>\n",
    "    <li>Less than or equal to: df['series'] <= value</li>\n",
    "    <li>Greater than: df['series'] > value</li>\n",
    "    <li>Greater than or equal to: df['series'] >= value</li>\n",
    "</ol>\n",
    "<li>These conditions can be used in several ways, most commonly inside .loc to select values with conditions.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8e11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db09f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a93623",
   "metadata": {},
   "source": [
    "### Using Pandas Method To Create a Boolean Mask\n",
    "\n",
    "<li>In the last couple lessons, we used Python boolean operators to create boolean masks to select subsets of data.</li>\n",
    "    \n",
    "<li>There are also a number of pandas methods that return boolean masks useful for exploring data.</li>\n",
    "\n",
    "<li>Two examples are the Series.isnull() method and Series.notnull() method.</li>\n",
    "<li>Series.isnull() method can be used to select either rows that contain null (or NaN) values for a certain column.</li>\n",
    "<li>Similarly, Series.notnull() method is used to select rows that do not contain null values for a certain column.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4dc258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713a727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "159b3d6f",
   "metadata": {},
   "source": [
    "#### Sorting Values\n",
    "<li>We can use the DataFrame.sort_values() method to sort the rows on a particular column.</li>\n",
    "<li>To do so, we pass the column name to the method:</li>\n",
    "<code>\n",
    "sorted_rows = df.sort_values(\"column_name\")\n",
    "</code>\n",
    "<li>By default, the sort_values() method will sort the rows in ascending order â€” from smallest to largest.</li>\n",
    "<li>To sort the rows in descending order instead, we can set the ascending parameter to False:</li>\n",
    "<code>\n",
    "    sorted_rows = df.sort_values(\"column_name\", ascending=False)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce9cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a755ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a7f068d",
   "metadata": {},
   "source": [
    "### String Manipulation In Pandas DataFrame\n",
    "\n",
    "<li>String manipulation is the process of changing, parsing, splitting, 'cleaning' or analyzing strings.</li>\n",
    "<li>As we know that sometimes, data in the string is not suitable for manipulating the analysis or get a description of the data.</li>\n",
    "<li>But Python is known for its ability to manipulate strings.</li>\n",
    "<li>Pandas provides us the ways to manipulate to modify and process string data-frame using some builtin functions.</li>\n",
    "<li>Some of the most useful pandas string processing functions are as follows:</li>\n",
    "<ol>\n",
    "    <li><b>lower()</b></li>\n",
    "    <li><b>upper()</b></li>\n",
    "    <li><b>strip()</b></li>\n",
    "    <li><b>split()</b></li>\n",
    "    <li><b>get_dummies()</b></li>\n",
    "    <li><b>startswith()</b></li>\n",
    "    <li><b>endswith()</b></li>\n",
    "    <li><b>replace()</b></li>\n",
    "    <li><b>contains()</b></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60212517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11577b89",
   "metadata": {},
   "source": [
    "#### GroupBy Functions\n",
    "<li>Pandas groupby is used for grouping the data according to the categories and apply a function to the categories.</li>\n",
    "<li>It also helps to aggregate data efficiently.</li>\n",
    "<li>Pandas dataframe.groupby() function is used to split the data into groups based on some criteria.</li>\n",
    "<code>\n",
    "    df.groupby(col_name, as_index, sort, dropna)\n",
    "</code>\n",
    "<li>It uses split, apply, combine principle to create a groupby dataframe.</li>\n",
    "<li>The groupby function accepts multiple parameters. Some of them are as follows:</li>\n",
    "<ol>\n",
    "    <li>col_name(required): the name of column against which you want to group elements.</li>\n",
    "    <li>as_index(optional): default = True, if you want to include groupby column as an index set it        to True else False.</li>\n",
    "    <li>sort(optional): default = True, if you want to sort the group based on keys then keep it as       True else False.</li>\n",
    "    <li>dropna(optional): default = True, if you keep it as false then it will also include Nan values     as a separate group.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ee661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9c2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b61091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0bc8dc7",
   "metadata": {},
   "source": [
    "### GroupBy Aggregation Functions\n",
    "<li>Here are some of the aggregating functions available in Pandas and quick summary of what it does.</li>\n",
    "<ol>\n",
    "    <li>mean(): Compute mean of groups for numeric columns</li>\n",
    "    <li>sum(): Compute sum of group values for numeric columns</li>\n",
    "    <li>size(): Compute group sizes</li>\n",
    "    <li>count(): Compute count of group</li>\n",
    "    <li>std(): Standard deviation of groups for numeric columns</li>\n",
    "    <li>var(): Compute variance of groups for numeric columns</li>\n",
    "    <li>describe(): Generates descriptive statistics</li>\n",
    "    <li>first(): Compute first of group values</li>\n",
    "    <li>last(): Compute last of group values</li>\n",
    "    <li>nth() : Take nth value, or a subset if n is a list</li>\n",
    "    <li>min(): Compute min of group values</li>\n",
    "    <li>max(): Compute max of group values</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1363153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f79d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916e52bc",
   "metadata": {},
   "source": [
    "####  Concatenating DataFrames\n",
    "<li>pandas.concat() function does all the heavy lifting of performing concatenation operations along with an axis</li>\n",
    "<li>If we want to join two individual dataframes and create a combined dataframe out of it, we can use concatenation operation for doing so.</li>\n",
    "<li>We can use concatenation operation along the rows(axis=0) as well as along the columns(axis = 1)</li>\n",
    "\n",
    "**syntax**\n",
    "\n",
    "<code>\n",
    "    pd.concat([df1,df2], axis, keys, ignore_index)\n",
    "</code>\n",
    "\n",
    "<li>df1 and df2 (required) are two dataframes which we want to merge.</li>\n",
    "<li>axis: axis to concatenate along, (possible values; 0(along the rows) and 1 (along the cols) default = 0 (along the rows).</li>\n",
    "<li>keys: sequence to add an identifier to the result indexes; default = None</li>\n",
    "<li>ignore_index: if True, do not use the index values along the concatenation axis; default = False</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8ee25",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes along the rows\n",
    "\n",
    "![](images/concat_rows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Name\": [\"Prabhat\", \"Hari\", \"Shyam\", \"Sita\", \"Mahima\"],\n",
    "                   \"Age\": [24, 34, 50, 32, 18],\n",
    "                   \"Address\": [\"Manigram\", \"Dhanewa\", \"Bardaghat\", \"Manglapur\", \"Bharatpur\"]\n",
    "                   })\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"Name\": [\"Sunil\", \"Bhawana\", \"Shiva\", \"Himal\", \"Dipen\"],\n",
    "                   \"Age\": [23, 22, 23, 25, 26],\n",
    "                   \"Address\": [\"Kathmandu\", \"Ramechap\", \"Kalangki\", \n",
    "                               \"Chaupatta\", \"Kirtipur\"]\n",
    "                   })\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2c266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "556d3226",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames along columns\n",
    "![](images/concat_cols.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\"Gender\": [\"Male\", \"Male\", \"Male\", \"Female\", \"Female\",\n",
    "                              \"Male\", \"Female\", \"Male\", \"Male\", \"Male\"], \n",
    "                   \"Height\": [1.6, 1.7, 1.5, 1.6, 1.65, 1.72, 1.43, 1.8, 1.71, 1.42],\n",
    "                   \"Weight\": [70, 67, 65, 45, 48, 73, 55, 82, 67, 55]})\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af367d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830fe55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
